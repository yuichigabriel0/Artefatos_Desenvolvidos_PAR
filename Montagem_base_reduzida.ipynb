{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Geração da Base Reduzida – Projeto PAR 2025\n",
        "\n",
        "Este documento descreve o processo utilizado para **montagem, limpeza, alinhamento e preparação** da base reduzida utilizada nos experimentos do projeto PAR 2025. Toda a execução foi realizada em Google Colab, com integração ao Google Drive.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Download da Base Original\n",
        "\n",
        "A primeira etapa consiste em baixar os arquivos disponibilizados por um dos integrantes do grupo via Google Drive.\n",
        "\n",
        "São baixados:\n",
        "\n",
        "* O arquivo ZIP com as imagens da base de treino (`training_set.zip`)\n",
        "* O arquivo `.txt` contendo as anotações (`training_set.txt`)\n",
        "\n",
        "O download foi realizado com `gdown` apontando para os IDs dos arquivos no Drive.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Extração do ZIP\n",
        "\n",
        "Após o download, o arquivo ZIP é extraído para um diretório específico dentro do `/content`, permitindo acesso às imagens originais.\n",
        "\n",
        "Essa extração é feita em duas etapas:\n",
        "\n",
        "1. Extração inicial para `training_set/`\n",
        "2. Extração organizada para `training_set_extracted/`, utilizada como base final\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Carregamento e Construção do DataFrame de Labels\n",
        "\n",
        "O arquivo `training_set.txt` contém as colunas:\n",
        "\n",
        "* `filename`\n",
        "* `top_color`\n",
        "* `bottom_color`\n",
        "* `gender`\n",
        "* `hat`\n",
        "* `bag`\n",
        "\n",
        "Ele é lido e associado a caminhos completos de arquivo, permitindo verificação e processamento das imagens.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Correção de Imagens Problemáticas\n",
        "\n",
        "Foram identificadas imagens com canais incorretos ou formato inconsistente. Essas imagens foram corrigidas manualmente utilizando Pillow, garantindo que todas passem a estar em RGB.\n",
        "\n",
        "As imagens corrigidas foram sobrescritas diretamente no dataset.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Corte da Base até a Última Imagem Válida\n",
        "\n",
        "Para evitar divergências entre quantidade de imagens e linhas do CSV, o DataFrame final é cortado até a **última imagem existente na pasta**.\n",
        "\n",
        "O resultado é salvo como:\n",
        "\n",
        "* `training_set_final.txt`\n",
        "\n",
        "Este arquivo é a versão oficial utilizada para formar a base reduzida.\n",
        "\n",
        "---\n",
        "\n",
        "## Balanceamento da Base com Augmentation\n",
        "\n",
        "### 6. Identificação de Classes Minoritárias\n",
        "- As colunas `top_color` e `bottom_color` foram analisadas.\n",
        "- Foram calculados percentis baixos para identificar:\n",
        "  - **Classes extremamente baixas**\n",
        "  - **Classes baixas**\n",
        "- Apenas essas classes receberiam augmentation.\n",
        "\n",
        "### 7. Definição dos Fatores de Augmentation\n",
        "- Classes extremamente baixas: até **16×**\n",
        "- Classes baixas: até **10×**\n",
        "- Fatores calculados de forma conservadora para evitar oversampling pesado.\n",
        "\n",
        "### 8. Técnicas de Augmentation Utilizadas\n",
        "- Flip horizontal  \n",
        "- Gaussian Noise  \n",
        "- ISO Noise  \n",
        "- Motion Blur  \n",
        "- Combinação (Blur + Noise)\n",
        "\n",
        "Cada técnica gera novas imagens artificiais nomeadas automaticamente.\n",
        "\n",
        "### 9. Geração da Nova Base Balanceada\n",
        "- Para cada imagem minoritária, diversas versões são geradas.\n",
        "- As entradas correspondentes são adicionadas a um novo dataframe.\n",
        "\n",
        "### 10. Visualização das Distribuições\n",
        "Foram gerados gráficos de barras para:\n",
        "\n",
        "- `top_color`\n",
        "- `bottom_color`\n",
        "- `gender`\n",
        "- `hat`\n",
        "- `bag`\n",
        "\n"
      ],
      "metadata": {
        "id": "rDB2XJKb9nVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PUXA DO DRIVE DO ARTHUR\n",
        "!pip install -q gdown\n",
        "\n",
        "training_zip_id = \"1RIL4aU_LP6VwYbBKl7cS9XM7w1EqJEge\"\n",
        "training_txt_id = \"1KsHdzNQBJmc6rWbB1wApOWD2krcuQN9L\"\n",
        "\n",
        "\n",
        "\n",
        "# Download\n",
        "!gdown --id $training_zip_id -O training_set.zip\n",
        "!gdown --id $training_txt_id -O training_set.txt\n",
        "\n",
        "# Extrair zip\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"training_set.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"training_set\")\n",
        "\n",
        "print(\"Arquivos baixados e extraídos com sucesso!\")\n"
      ],
      "metadata": {
        "id": "6VZmtXQL8kg0",
        "outputId": "aac55b56-b71c-44ac-ee77-539a04b44fd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1RIL4aU_LP6VwYbBKl7cS9XM7w1EqJEge\n",
            "From (redirected): https://drive.google.com/uc?id=1RIL4aU_LP6VwYbBKl7cS9XM7w1EqJEge&confirm=t&uuid=38a04426-848e-486e-b50b-50f82b18678c\n",
            "To: /content/training_set.zip\n",
            "100% 188M/188M [00:02<00:00, 88.5MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KsHdzNQBJmc6rWbB1wApOWD2krcuQN9L\n",
            "To: /content/training_set.txt\n",
            "100% 6.39M/6.39M [00:00<00:00, 26.7MB/s]\n",
            "Arquivos baixados e extraídos com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EXTRAI ZIP\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Configurações\n",
        "zip_path = \"/content/training_set.zip\"\n",
        "extract_dir = \"/content/training_set_extracted\"\n",
        "\n",
        "# Criar pasta de extração\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Extrair ZIP\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(\"ZIP extraído para\", extract_dir)\n",
        "\n",
        "# Ler CSV de labels\n",
        "labels_df = pd.read_csv(\"training_set.txt\", sep=\",\", header=None)\n",
        "labels_df.columns = [\"filename\", \"top_color\", \"bottom_color\", \"gender\", \"hat\", \"bag\"]\n",
        "\n",
        "IMG_DIR = os.path.join(extract_dir, \"training_set\")\n",
        "labels_df[\"filepath\"] = labels_df[\"filename\"].apply(lambda x: os.path.join(IMG_DIR, x))\n",
        "\n",
        "# Conferir\n",
        "print(labels_df.head())\n"
      ],
      "metadata": {
        "id": "uisQuW7v8koM",
        "outputId": "0602dadc-bcc4-486d-a073-e12e2aff3c02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZIP extraído para /content/training_set_extracted\n",
            "  filename  top_color  bottom_color  gender  hat  bag  \\\n",
            "0    1.jpg          1             1       0    0    0   \n",
            "1    2.jpg          7             1       1    0    0   \n",
            "2    3.jpg          4             2       0    0    0   \n",
            "3    4.jpg          1             1       0    0    0   \n",
            "4    5.jpg          1             1       0    0    0   \n",
            "\n",
            "                                            filepath  \n",
            "0  /content/training_set_extracted/training_set/1...  \n",
            "1  /content/training_set_extracted/training_set/2...  \n",
            "2  /content/training_set_extracted/training_set/3...  \n",
            "3  /content/training_set_extracted/training_set/4...  \n",
            "4  /content/training_set_extracted/training_set/5...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CORRIGE IMAGENS PROBLEMATICAS\n",
        "from PIL import Image\n",
        "\n",
        "problem_imgs = [\"000_45_1.jpg\", \"000_45_2.jpg\"]\n",
        "for img_name in problem_imgs:\n",
        "    img_path = os.path.join(IMG_DIR, img_name)\n",
        "    im = Image.open(img_path)\n",
        "    rgb_im = im.convert('RGB')  # garante 3 canais\n",
        "    rgb_im.save(img_path, \"JPEG\")  # sobrescreve como JPEG\n"
      ],
      "metadata": {
        "id": "LYYyfCkK83U1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Caminho da pasta de imagens\n",
        "IMG_DIR = \"/content/training_set/training_set\"\n",
        "\n",
        "# Ler CSV original\n",
        "labels_df = pd.read_csv(\"training_set.txt\", sep=\",\", header=None)\n",
        "labels_df.columns = [\"filename\", \"top_color\", \"bottom_color\", \"gender\", \"hat\", \"bag\"]\n",
        "\n",
        "# Função para ordenação alfa-numérica\n",
        "def sorted_nicely(file_list):\n",
        "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
        "    return sorted(file_list, key=alphanum_key)\n",
        "\n",
        "# Listar arquivos existentes na pasta\n",
        "existing_files = os.listdir(IMG_DIR)\n",
        "existing_files_sorted = sorted_nicely(existing_files)\n",
        "\n",
        "# Filtrar CSV para imagens existentes\n",
        "labels_df = labels_df[labels_df[\"filename\"].isin(existing_files_sorted)].reset_index(drop=True)\n",
        "\n",
        "# Ordenar CSV alfa-numérico\n",
        "sorted_filenames = sorted_nicely(labels_df[\"filename\"].tolist())\n",
        "labels_df = labels_df.set_index(\"filename\").loc[sorted_filenames].reset_index()\n",
        "\n",
        "# Salvar CSV alinhado antes de cortar\n",
        "labels_df.to_csv(\"training_set_aligned.txt\", index=False)\n",
        "print(\"TXT alinhado salvo como 'training_set_aligned.txt'\")\n",
        "\n",
        "# Encontrar a última imagem da pasta\n",
        "last_image_name = existing_files_sorted[-1]\n",
        "\n",
        "# Cortar o CSV até a última imagem\n",
        "last_idx = labels_df[labels_df[\"filename\"] == last_image_name].index[0]\n",
        "labels_df_final = labels_df.iloc[:last_idx+1].reset_index(drop=True)\n",
        "\n",
        "# Salvar CSV final cortado\n",
        "labels_df_final.to_csv(\"training_set_final.txt\", index=False)\n",
        "print(\"TXT final cortado salvo como 'training_set_final.txt', até a última imagem:\", last_image_name)\n",
        "\n",
        "# Conferir\n",
        "print(labels_df_final.tail(5))\n"
      ],
      "metadata": {
        "id": "J0MIciM28ktl",
        "outputId": "fe0ad0a8-9517-414b-9109-f4b0c01aafde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TXT alinhado salvo como 'training_set_aligned.txt'\n",
            "TXT final cortado salvo como 'training_set_final.txt', até a última imagem: VideoX_412_135_3.jpg\n",
            "                   filename  top_color  bottom_color  gender  hat  bag\n",
            "22284  VideoX_412_134_1.jpg         10             4       0    0    1\n",
            "22285  VideoX_412_134_2.jpg          4             2       0    1    0\n",
            "22286  VideoX_412_135_1.jpg         11             4       0    0    1\n",
            "22287  VideoX_412_135_2.jpg          4             2       0    1    0\n",
            "22288  VideoX_412_135_3.jpg          4             2       0    1    1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations\n"
      ],
      "metadata": {
        "id": "rC7qHmFb83XU",
        "outputId": "41f6587b-697c-4024-a734-d1b747930288",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (2.0.8)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations) (1.16.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations) (6.0.3)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.11.10)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations) (4.12.0.88)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (4.2.3)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "import random\n",
        "\n",
        "# Definir seed para reprodutibilidade\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Diretório e leitura do dataset\n",
        "IMG_DIR = \"/content/training_set/training_set\"\n",
        "labels_df = pd.read_csv(\"training_set_final.txt\", sep=\",\")\n",
        "labels_df.columns = [\"filename\", \"top_color\", \"bottom_color\", \"gender\", \"hat\", \"bag\"]\n",
        "\n",
        "print(\"=== IDENTIFICANDO APENAS AS CLASSES MAIS BAIXAS ===\")\n",
        "\n",
        "# Analisar distribuição das classes\n",
        "top_counts = labels_df['top_color'].value_counts().sort_index()\n",
        "bottom_counts = labels_df['bottom_color'].value_counts().sort_index()\n",
        "\n",
        "print(\"Distribuição original TOP_COLOR:\")\n",
        "print(top_counts)\n",
        "print(\"\\nDistribuição original BOTTOM_COLOR:\")\n",
        "print(bottom_counts)\n",
        "\n",
        "# Estratégia mais rigorosa - identificar apenas classes realmente baixas\n",
        "# Usar percentis baixos para identificar classes minoritárias\n",
        "top_10th_percentile = np.percentile(top_counts.values, 10)  # 10% menores\n",
        "top_20th_percentile = np.percentile(top_counts.values, 20)  # 20% menores\n",
        "\n",
        "bottom_10th_percentile = np.percentile(bottom_counts.values, 30)\n",
        "bottom_20th_percentile = np.percentile(bottom_counts.values, 40)\n",
        "\n",
        "# Classes extremamente baixas (bottom 10%)\n",
        "VERY_LOW_TOP = top_counts[top_counts <= top_10th_percentile].index.tolist()\n",
        "VERY_LOW_BOTTOM = bottom_counts[bottom_counts <= bottom_10th_percentile].index.tolist()\n",
        "\n",
        "# Classes baixas (bottom 20% mas acima do 10%)\n",
        "LOW_TOP = top_counts[(top_counts > top_10th_percentile) & (top_counts <= top_20th_percentile)].index.tolist()\n",
        "LOW_BOTTOM = bottom_counts[(bottom_counts > bottom_10th_percentile) & (bottom_counts <= bottom_20th_percentile)].index.tolist()\n",
        "\n",
        "print(f\"\\n=== CLASSES SELECIONADAS PARA AUGMENTATION ===\")\n",
        "print(f\"TOP_COLOR - Extremamente baixas (≤{top_10th_percentile:.0f}): {VERY_LOW_TOP}\")\n",
        "print(f\"Counts: {[top_counts[c] for c in VERY_LOW_TOP]}\")\n",
        "print(f\"TOP_COLOR - Baixas ({top_10th_percentile:.0f} < x ≤ {top_20th_percentile:.0f}): {LOW_TOP}\")\n",
        "print(f\"Counts: {[top_counts[c] for c in LOW_TOP]}\")\n",
        "\n",
        "print(f\"\\nBOTTOM_COLOR - Extremamente baixas (≤{bottom_10th_percentile:.0f}): {VERY_LOW_BOTTOM}\")\n",
        "print(f\"Counts: {[bottom_counts[c] for c in VERY_LOW_BOTTOM]}\")\n",
        "print(f\"BOTTOM_COLOR - Baixas ({bottom_10th_percentile:.0f} < x ≤ {bottom_20th_percentile:.0f}): {LOW_BOTTOM}\")\n",
        "print(f\"Counts: {[bottom_counts[c] for c in LOW_BOTTOM]}\")\n",
        "\n",
        "# Função mais conservadora para augmentation\n",
        "def calculate_conservative_augmentation(class_count, class_level, max_count_in_dataset):\n",
        "    \"\"\"Calcula augmentation de forma conservadora baseado no percentil\"\"\"\n",
        "    if class_level == \"very_low\":\n",
        "        # Para classes extremamente baixas: máximo 8x\n",
        "        target_ratio = 0.30  # Tentar chegar a 15% da classe mais comum\n",
        "        max_factor = 16\n",
        "    elif class_level == \"low\":\n",
        "        # Para classes baixas: máximo 5x\n",
        "        target_ratio = 0.15  # Tentar chegar a 12% da classe mais comum\n",
        "        max_factor = 10\n",
        "    else:\n",
        "        return 1  # Não aumentar outras classes\n",
        "\n",
        "    target_count = int(max_count_in_dataset * target_ratio)\n",
        "    if class_count >= target_count:\n",
        "        return 1\n",
        "\n",
        "    factor = min(max_factor, int(target_count / class_count))\n",
        "    return max(1, factor)\n",
        "\n",
        "# Definir transformações\n",
        "augmentations = {\n",
        "    'noise': A.AdditiveNoise(\n",
        "        noise_type=\"gaussian\",\n",
        "        spatial_mode=\"shared\",\n",
        "        noise_params={\"mean_range\":[0,0],\"std_range\":[0.05,0.15]},\n",
        "        approximation=1\n",
        "    ),\n",
        "    'blur': A.MotionBlur(\n",
        "        blur_limit=7,\n",
        "        p=1.0\n",
        "    ),\n",
        "    'ISONoise': A.ISONoise(\n",
        "      color_shift=[0.01, 0.05],\n",
        "      intensity=[0.1, 0.5]\n",
        "  )\n",
        "}\n",
        "\n",
        "print(f\"\\nProcessando dataset com {len(labels_df)} imagens...\")\n",
        "\n",
        "# Lista para construir o novo dataset\n",
        "new_dataset_rows = []\n",
        "augmentation_stats = {\"flip\": 0, \"noise\": 0, \"ISONoise\": 0, \"blur\": 0, \"combined\": 0}\n",
        "\n",
        "# Contadores para monitoramento\n",
        "classes_processed = set()\n",
        "images_augmented = 0\n",
        "\n",
        "# Loop nas imagens\n",
        "for index, row in labels_df.iterrows():\n",
        "    # Sempre adicionar a imagem original primeiro\n",
        "    new_dataset_rows.append(row)\n",
        "\n",
        "    # Determinar se a imagem deve ser aumentada\n",
        "    top_class = int(row[\"top_color\"])\n",
        "    bottom_class = int(row[\"bottom_color\"])\n",
        "\n",
        "    aug_factor = 1\n",
        "    is_augmentable = False\n",
        "    reason = []\n",
        "\n",
        "    # Verificar apenas classes realmente baixas para top_color\n",
        "    if top_class in VERY_LOW_TOP:\n",
        "        top_factor = calculate_conservative_augmentation(\n",
        "            top_counts[top_class], \"very_low\", top_counts.max()\n",
        "        )\n",
        "        aug_factor = max(aug_factor, top_factor)\n",
        "        is_augmentable = True\n",
        "        reason.append(f\"top_very_low_{top_class}\")\n",
        "        classes_processed.add(f\"top_{top_class}\")\n",
        "    elif top_class in LOW_TOP:\n",
        "        top_factor = calculate_conservative_augmentation(\n",
        "            top_counts[top_class], \"low\", top_counts.max()\n",
        "        )\n",
        "        aug_factor = max(aug_factor, top_factor)\n",
        "        is_augmentable = True\n",
        "        reason.append(f\"top_low_{top_class}\")\n",
        "        classes_processed.add(f\"top_{top_class}\")\n",
        "\n",
        "    # Verificar apenas classes realmente baixas para bottom_color\n",
        "    if bottom_class in VERY_LOW_BOTTOM:\n",
        "        bottom_factor = calculate_conservative_augmentation(\n",
        "            bottom_counts[bottom_class], \"very_low\", bottom_counts.max()\n",
        "        )\n",
        "        aug_factor = max(aug_factor, bottom_factor)\n",
        "        is_augmentable = True\n",
        "        reason.append(f\"bottom_very_low_{bottom_class}\")\n",
        "        classes_processed.add(f\"bottom_{bottom_class}\")\n",
        "    elif bottom_class in LOW_BOTTOM:\n",
        "        bottom_factor = calculate_conservative_augmentation(\n",
        "            bottom_counts[bottom_class], \"low\", bottom_counts.max()\n",
        "        )\n",
        "        aug_factor = max(aug_factor, bottom_factor)\n",
        "        is_augmentable = True\n",
        "        reason.append(f\"bottom_low_{bottom_class}\")\n",
        "        classes_processed.add(f\"bottom_{bottom_class}\")\n",
        "\n",
        "    # Aplicar augmentation apenas se for classe realmente baixa\n",
        "    if is_augmentable and aug_factor > 1:\n",
        "        if images_augmented < 10:  # Log das primeiras 10 para debug\n",
        "            print(f\"Imagem {row['filename']}: {' + '.join(reason)} -> fator {aug_factor}\")\n",
        "\n",
        "        img_path = os.path.join(IMG_DIR, row[\"filename\"])\n",
        "\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"Imagem não encontrada: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"Erro ao carregar imagem: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        base_name = os.path.splitext(row[\"filename\"])[0]\n",
        "        ext = os.path.splitext(row[\"filename\"])[1]\n",
        "\n",
        "        # Lista de técnicas\n",
        "        aug_techniques = ['flip', 'noise', 'ISONoise', 'blur', 'combined']\n",
        "\n",
        "        # Criar augmentations\n",
        "        for i in range(aug_factor - 1):\n",
        "            technique = aug_techniques[i % len(aug_techniques)]\n",
        "\n",
        "            if technique == 'flip':\n",
        "                augmented_img = cv2.flip(img_rgb, 1)\n",
        "                suffix = \"flipped\"\n",
        "\n",
        "            elif technique == 'combined':\n",
        "                # Combinar transformações para classes muito baixas\n",
        "                combined_aug = A.Compose([\n",
        "                    augmentations['blur'],\n",
        "                    augmentations['noise']\n",
        "                ])\n",
        "                augmented = combined_aug(image=img_rgb)\n",
        "                augmented_img = augmented[\"image\"]\n",
        "                suffix = \"combined\"\n",
        "\n",
        "            else:\n",
        "                # Aplicar transformação específica\n",
        "                augmented = augmentations[technique](image=img_rgb)\n",
        "                augmented_img = augmented[\"image\"]\n",
        "                suffix = technique\n",
        "\n",
        "            # Gerar nome único\n",
        "            aug_filename = f\"{base_name}_{suffix}_{i+1}{ext}\"\n",
        "            aug_path = os.path.join(IMG_DIR, aug_filename)\n",
        "\n",
        "            # Salvar imagem\n",
        "            augmented_bgr = cv2.cvtColor(augmented_img, cv2.COLOR_RGB2BGR)\n",
        "            cv2.imwrite(aug_path, augmented_bgr)\n",
        "\n",
        "            # Adicionar ao dataset\n",
        "            aug_entry = row.copy()\n",
        "            aug_entry[\"filename\"] = aug_filename\n",
        "            new_dataset_rows.append(aug_entry)\n",
        "\n",
        "            # Atualizar estatísticas\n",
        "            augmentation_stats[technique] += 1\n",
        "\n",
        "        images_augmented += 1\n",
        "\n",
        "    # Mostrar progresso\n",
        "    if index % 500 == 0:\n",
        "        print(f\"Processadas {index} imagens... Augmentadas: {images_augmented}\")\n",
        "\n",
        "# Criar DataFrame final\n",
        "augmented_labels_df = pd.DataFrame(new_dataset_rows)\n",
        "augmented_labels_df.to_csv(\"training_set_balanced.txt\", index=False)\n",
        "\n",
        "print(f\"\\n=== PROCESSAMENTO CONCLUÍDO ===\")\n",
        "print(f\"Classes processadas: {sorted(classes_processed)}\")\n",
        "print(f\"Imagens que receberam augmentation: {images_augmented}\")\n",
        "\n",
        "augmented_count = len(augmented_labels_df) - len(labels_df)\n",
        "print(f\"Novas imagens criadas: {augmented_count}\")\n",
        "print(f\"Dataset original: {len(labels_df)} imagens\")\n",
        "print(f\"Dataset balanceado: {len(augmented_labels_df)} imagens\")\n",
        "print(f\"Aumento total: {len(augmented_labels_df)/len(labels_df):.2f}x\")\n",
        "\n",
        "# Estatísticas detalhadas\n",
        "print(f\"\\n=== TIPOS DE AUGMENTATION APLICADOS ===\")\n",
        "for aug_type, count in augmentation_stats.items():\n",
        "    if count > 0:\n",
        "        print(f\"{aug_type.capitalize()}: {count}\")\n",
        "\n",
        "# Análise das distribuições finais - foco nas classes que foram aumentadas\n",
        "new_top_counts = augmented_labels_df['top_color'].value_counts().sort_index()\n",
        "new_bottom_counts = augmented_labels_df['bottom_color'].value_counts().sort_index()\n",
        "\n",
        "print(f\"\\n=== VERIFICAÇÃO: CLASSES QUE FORAM AUMENTADAS ===\")\n",
        "\n",
        "if VERY_LOW_TOP or LOW_TOP:\n",
        "    print(\"TOP_COLOR - Classes aumentadas:\")\n",
        "    for cls in VERY_LOW_TOP + LOW_TOP:\n",
        "        antes = top_counts[cls]\n",
        "        depois = new_top_counts[cls]\n",
        "        print(f\"  Classe {cls}: {antes} → {depois} ({depois/antes:.1f}x)\")\n",
        "\n",
        "if VERY_LOW_BOTTOM or LOW_BOTTOM:\n",
        "    print(\"\\nBOTTOM_COLOR - Classes aumentadas:\")\n",
        "    for cls in VERY_LOW_BOTTOM + LOW_BOTTOM:\n",
        "        antes = bottom_counts[cls]\n",
        "        depois = new_bottom_counts[cls]\n",
        "        print(f\"  Classe {cls}: {antes} → {depois} ({depois/antes:.1f}x)\")\n",
        "\n",
        "print(f\"\\nArquivo salvo como: training_set_balanced.txt\")"
      ],
      "metadata": {
        "id": "dKDVUaTQ83ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DISTRIBUIÇÃO DA BASE\n",
        "import subprocess, sys\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Caminho do TXT\n",
        "txt_path = \"/content/training_set_balanced.txt\"\n",
        "\n",
        "print(\"Lendo arquivo TXT...\\n\")\n",
        "df = pd.read_csv(txt_path, header=0, sep=\",\")\n",
        "df.columns = [\"filename\", \"top_color\", \"bottom_color\", \"gender\", \"hat\", \"bag\"]\n",
        "\n",
        "print(\"Arquivo carregado!\")\n",
        "print(f\"Total de imagens: {len(df):,}\\n\")\n",
        "\n",
        "\n",
        "# Função de contagem e plot\n",
        "def contar_e_plotar(coluna, titulo):\n",
        "    contagem = df[coluna].value_counts().sort_index()\n",
        "    porcentagem = contagem / contagem.sum() * 100\n",
        "\n",
        "    print(f\"=== {titulo} ===\")\n",
        "    print(contagem)\n",
        "    print(porcentagem.round(2))\n",
        "    print()\n",
        "\n",
        "    labels = contagem.index.astype(str)\n",
        "    valores = contagem.values\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    bars = plt.bar(labels, valores, color=plt.cm.tab10.colors)\n",
        "\n",
        "    # Exibir valores e % acima das barras\n",
        "    for i, (v, p) in enumerate(zip(valores, porcentagem)):\n",
        "        plt.text(i, v + max(valores)*0.01, f\"{v}\\n({p:.1f}%)\",\n",
        "                 ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "    plt.title(f\"Distribuição - {titulo}\")\n",
        "    plt.xlabel(\"Classe (número)\")\n",
        "    plt.ylabel(\"Quantidade\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Gerar gráficos\n",
        "contar_e_plotar(\"top_color\", \"Top Color (Parte Superior)\")\n",
        "contar_e_plotar(\"bottom_color\", \"Bottom Color (Parte Inferior)\")\n",
        "contar_e_plotar(\"gender\", \"Gênero\")\n",
        "contar_e_plotar(\"hat\", \"Uso de Chapéu\")\n",
        "contar_e_plotar(\"bag\", \"Uso de Bolsa\")\n",
        "\n",
        "print(\"Análise concluída!\")\n"
      ],
      "metadata": {
        "id": "s-2HIk_29GAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Caminho da pasta com as imagens\n",
        "img_folder = \"/content/training_set/training_set\"\n",
        "\n",
        "# Caminho do arquivo de labels\n",
        "labels_file = \"/content/training_set_balanced.txt\"\n",
        "\n",
        "# Nome do zip final\n",
        "zip_filename = \"training_balanced.zip\"\n",
        "\n",
        "# Criar o ZIP\n",
        "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    # Adicionar todas as imagens da pasta\n",
        "    for root, dirs, files_in_dir in os.walk(img_folder):\n",
        "        for file in files_in_dir:\n",
        "            file_path = os.path.join(root, file)\n",
        "            # Caminho relativo para dentro do ZIP\n",
        "            arcname = os.path.relpath(file_path, os.path.dirname(img_folder))\n",
        "            zipf.write(file_path, arcname)\n",
        "\n",
        "    # Adicionar o arquivo de labels\n",
        "    zipf.write(labels_file, os.path.basename(labels_file))\n",
        "\n",
        "# Fazer download do ZIP\n",
        "files.download(zip_filename)\n"
      ],
      "metadata": {
        "id": "RZ8VyIKT9JMV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}